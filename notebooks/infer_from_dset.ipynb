{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import eval\n",
    "from ml_collections.config_dict import ConfigDict\n",
    "\n",
    "import models.diffusion\n",
    "from models.diffusion_utils import generate\n",
    "from models.train_utils import create_input_iter\n",
    "from models.flows import nsf, maf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('/mnt/home/tnguyen/default.mplstyle')\n",
    "\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/mnt/ceph/users/tnguyen/dark_camels/point-cloud-diffusion-logging'\n",
    "vdm_name = 'vdm/dazzling-leaf-75'\n",
    "flows_name = 'flows/earthy-dream-105'\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "steps = 500\n",
    "batch_size = 256\n",
    "num_particles = 100\n",
    "num_features = 8\n",
    "num_repeats = 100\n",
    "conditioning_parameters = ['halo_mvir', 'inv_wdm_mass', 'log_sn1', 'log_sn2', 'log_agn1']\n",
    "dataset_root = '/mnt/ceph/users/tnguyen/dark_camels/point-cloud-diffusion-datasets/processed_datasets/'\n",
    "dataset_name = 'mw_zooms-wdm-dmprop/nmax100-vmaxtilde-pad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "x, mask, conditioning, norm_dict = datasets.get_nbody_data(\n",
    "    dataset_root, dataset_name, num_features, num_particles,\n",
    "    conditioning_parameters=conditioning_parameters\n",
    ")\n",
    "# unnormalized xb\n",
    "x = x * norm_dict['std'] + norm_dict['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n",
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    }
   ],
   "source": [
    "path_to_vdm = Path(os.path.join(root, vdm_name))\n",
    "path_to_flows = Path(os.path.join(root, flows_name))\n",
    "\n",
    "# load the vdm and the flows\n",
    "vdm, vdm_params = models.diffusion.VariationalDiffusionModel.from_path_to_model(\n",
    "    path_to_model=path_to_vdm, norm_dict=norm_dict)\n",
    "flows, flows_params = nsf.NeuralSplineFlow.from_path_to_model(\n",
    "    path_to_model=path_to_flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.vmap, in_axes=(0, None, 0))\n",
    "def sample_from_flow(context, n_samples=10_000, key=jax.random.PRNGKey(42)):\n",
    "    \"\"\"Helper function to sample from the flow model.\n",
    "    \"\"\"\n",
    "    def sample_fn(flows):\n",
    "        x_samples = flows.sample(\n",
    "            num_samples=n_samples, rng=key, \n",
    "            context=context * jnp.ones((n_samples, 1)))\n",
    "        return x_samples\n",
    "\n",
    "    x_samples = nn.apply(sample_fn, flows)(flows_params)\n",
    "    return x_samples\n",
    "\n",
    "@partial(jax.vmap, in_axes=(0, None))\n",
    "def create_mask(n, num_particles):\n",
    "    # Create an array [0, 1, 2, ..., num_particles-1]\n",
    "    indices = jnp.arange(num_particles)\n",
    "    # Compare each index to n, resulting in True (1) if index < n, else False (0)\n",
    "    mask = indices < n\n",
    "    return mask.astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# iterate over the dataset and generate samples\n",
    "truth_samples = []\n",
    "gen_samples = []\n",
    "gen_cond = []\n",
    "gen_mask = []\n",
    "\n",
    "dset = datasets.make_dataloader(\n",
    "    x, conditioning, mask, batch_size=batch_size, shuffle=False, repeat=False)\n",
    "dset = create_input_iter(dset)\n",
    "\n",
    "for batch in tqdm(dset):\n",
    "    x_batch, cond_batch, mask_batch = batch[0], batch[1], batch[2]\n",
    "    x_batch = jnp.repeat(x_batch[0], num_repeats, axis=0)\n",
    "    cond_batch = jnp.repeat(cond_batch[0], num_repeats, axis=0)\n",
    "    mask_batch = jnp.repeat(mask_batch[0], num_repeats, axis=0)\n",
    "\n",
    "    # generate the number of particles using the flows\n",
    "    num_subhalos = 10**sample_from_flow(\n",
    "        cond_batch, 1, jax.random.split(rng, len(cond_batch))).squeeze()\n",
    "    num_subhalos = jnp.clip(num_subhalos, 1, num_particles)\n",
    "    num_subhalos = jnp.round(num_subhalos).astype(jnp.int32)    \n",
    "    mask_batch = create_mask(num_subhalos, num_particles)\n",
    "\n",
    "    # generate using the VDM\n",
    "    gen_samples.append(\n",
    "        eval.generate_samples(\n",
    "            vdm=vdm,\n",
    "            params=vdm_params,\n",
    "            rng=rng,\n",
    "            n_samples=len(cond_batch),\n",
    "            n_particles=num_particles,\n",
    "            conditioning=cond_batch,\n",
    "            mask=mask_batch,\n",
    "            steps=steps,\n",
    "            norm_dict=norm_dict,\n",
    "            boxsize=1,  # doesn't matter\n",
    "        )\n",
    "    )\n",
    "    gen_cond.append(cond_batch)\n",
    "    gen_mask.append(mask_batch)\n",
    "    truth_samples.append(x_batch)\n",
    "\n",
    "gen_samples = jnp.concatenate(gen_samples, axis=0)\n",
    "gen_cond = jnp.concatenate(gen_cond, axis=0)\n",
    "gen_mask = jnp.concatenate(gen_mask, axis=0)\n",
    "truth_samples = jnp.concatenate(truth_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the samples\n",
    "out_root = '/mnt/home/tnguyen/ceph/dark_camels/point-cloud-diffusion-outputs'\n",
    "out_path = os.path.join(\n",
    "    out_root, f'vdm-flows/{os.path.basename(vdm_name)}_{os.path.basename(flows_name)}.npz')\n",
    "np.savez(\n",
    "    out_path, samples=gen_samples, cond=gen_cond, \n",
    "    mask=gen_mask, truth=truth_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy-diffusion-release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
