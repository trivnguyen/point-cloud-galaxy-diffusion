{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import eval\n",
    "from ml_collections.config_dict import ConfigDict\n",
    "\n",
    "import models.diffusion\n",
    "from models.diffusion_utils import generate\n",
    "from models.train_utils import create_input_iter\n",
    "from analysis_utils import envs\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('/mnt/home/tnguyen/default.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wdm/pious-darkness-68'\n",
    "rng = jax.random.PRNGKey(42)\n",
    "steps = 500\n",
    "batch_size = 128\n",
    "num_particles = 50\n",
    "num_repeats = 10\n",
    "dataset_root = None\n",
    "dataset_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    }
   ],
   "source": [
    "# load the config\n",
    "path_to_model = envs.DEFAULT_LOGGING_DIR / model_name\n",
    "with open(path_to_model / \"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config = ConfigDict(config)\n",
    "\n",
    "if dataset_root is None:\n",
    "    dataset_root = config.data.dataset_root\n",
    "if dataset_name is None:\n",
    "    dataset_name = config.data.dataset_name\n",
    "\n",
    "# read in the dataset\n",
    "x, mask, conditioning, norm_dict = datasets.get_nbody_data(\n",
    "    dataset_root,\n",
    "    dataset_name,\n",
    "    config.data.n_features,\n",
    "    config.data.n_particles,\n",
    "    conditioning_parameters=config.data.conditioning_parameters,\n",
    ")\n",
    "\n",
    "# unnormalized x\n",
    "x = x * norm_dict['std'] + norm_dict['mean']\n",
    "\n",
    "# load the model\n",
    "vdm, params = models.diffusion.VariationalDiffusionModel.from_path_to_model(\n",
    "    path_to_model=path_to_model, norm_dict=norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# iterate over the dataset and generate samples\n",
    "truth_samples = []\n",
    "gen_samples = []\n",
    "gen_cond = []\n",
    "gen_mask = []\n",
    "\n",
    "dset = datasets.make_dataloader(\n",
    "    x, conditioning, mask, batch_size=batch_size, shuffle=False, repeat=False)\n",
    "dset = create_input_iter(dset)\n",
    "\n",
    "for batch in tqdm(dset):\n",
    "    x_batch, cond_batch, mask_batch = batch[0], batch[1], batch[2]\n",
    "    x_batch = jnp.repeat(x_batch[0], num_repeats, axis=0)\n",
    "    cond_batch = jnp.repeat(cond_batch[0], num_repeats, axis=0)\n",
    "    mask_batch = jnp.repeat(mask_batch[0], num_repeats, axis=0)\n",
    "    gen_samples.append(\n",
    "        eval.generate_samples(\n",
    "            vdm=vdm,\n",
    "            params=params,\n",
    "            rng=rng,\n",
    "            n_samples=len(cond_batch),\n",
    "            n_particles=num_particles,\n",
    "            conditioning=cond_batch,\n",
    "            mask=mask_batch,\n",
    "            steps=steps,\n",
    "            norm_dict=norm_dict,\n",
    "            boxsize=1,  # doesn't matter\n",
    "        )\n",
    "    )\n",
    "    gen_cond.append(cond_batch)\n",
    "    gen_mask.append(mask_batch)\n",
    "    truth_samples.append(x_batch)\n",
    "\n",
    "gen_samples = jnp.concatenate(gen_samples, axis=0)\n",
    "gen_cond = jnp.concatenate(gen_cond, axis=0)\n",
    "gen_mask = jnp.concatenate(gen_mask, axis=0)\n",
    "truth_samples = jnp.concatenate(truth_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the samples\n",
    "out_path = envs.DEFAULT_OUTPUT_DIR / (model_name + '.npz')\n",
    "np.savez(\n",
    "    out_path, samples=gen_samples, cond=gen_cond, mask=gen_mask, truth=truth_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy-diffusion-release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
