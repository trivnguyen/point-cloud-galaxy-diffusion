{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import eval\n",
    "import models.diffusion\n",
    "from models.diffusion_utils import generate\n",
    "from models.train_utils import create_input_iter\n",
    "\n",
    "from ml_collections.config_dict import ConfigDict\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('/mnt/home/tnguyen/default.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    }
   ],
   "source": [
    "path_to_model = Path(\"/mnt/ceph/users/tnguyen/dark_camels/point-cloud-diffusion-logging/\"\\\n",
    "    \"cosmology/effortless-meadow-54/\")\n",
    "\n",
    "with open(path_to_model / \"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config = ConfigDict(config)\n",
    "\n",
    "train_ds, norm_dict = datasets.load_data(\n",
    "    config.data.dataset,\n",
    "    config.data.dataset_root,\n",
    "    config.data.dataset_name,\n",
    "    config.data.n_features,\n",
    "    config.data.n_particles,\n",
    "    config.training.batch_size,\n",
    "    config.seed,\n",
    "    shuffle=True,\n",
    "    repeat=False,\n",
    "    split=\"train\",\n",
    "    conditioning_parameters=config.data.conditioning_parameters,\n",
    ")\n",
    "\n",
    "vdm, params = models.diffusion.VariationalDiffusionModel.from_path_to_model(\n",
    "    path_to_model=path_to_model, norm_dict=norm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 takes 4.399191856384277 seconds\n",
      "Iteration 1 takes 4.00584077835083 seconds\n",
      "Iteration 2 takes 2.6433539390563965 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3106790/1049224182.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  true_samples = np.array(true_samples)\n",
      "/tmp/ipykernel_3106790/1049224182.py:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  generated_samples = np.array(generated_samples)\n",
      "/tmp/ipykernel_3106790/1049224182.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  conditioning_samples = np.array(conditioning_samples)\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "batch_size = config.training.batch_size\n",
    "n_particles = config.data.n_particles\n",
    "steps = 500\n",
    "boxsize = 1\n",
    "\n",
    "batches = create_input_iter(train_ds)\n",
    "\n",
    "true_samples = []\n",
    "generated_samples = []\n",
    "conditioning_samples = []\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    t0 = time.time()\n",
    "    x_batch, conditioning_batch, mask_batch = batch\n",
    "    true_samples.append(x_batch[0] * norm_dict[\"std\"] + norm_dict[\"mean\"])\n",
    "    generated_samples.append(\n",
    "        eval.generate_samples(\n",
    "            vdm=vdm,\n",
    "            params=params,\n",
    "            rng=rng,\n",
    "            n_samples=len(conditioning_batch[0]),\n",
    "            n_particles=n_particles,\n",
    "            conditioning=conditioning_batch[0],\n",
    "            mask=mask_batch[0],\n",
    "            steps=steps,\n",
    "            norm_dict=norm_dict,\n",
    "            boxsize=boxsize,\n",
    "        )\n",
    "    )\n",
    "    conditioning_samples.append(conditioning_batch[0])\n",
    "    print(f\"Iteration {i} takes {time.time() - t0} seconds\")\n",
    "\n",
    "# convert back to Numpy arrays because the person who wrote this code hates JAX\n",
    "true_samples = np.array(true_samples)\n",
    "generated_samples = np.array(generated_samples)\n",
    "conditioning_samples = np.array(conditioning_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_samples = np.vstack(true_samples)\n",
    "generated_samples = np.vstack(generated_samples)\n",
    "conditioning_samples = np.vstack(conditioning_samples)\n",
    "\n",
    "# save the samples\n",
    "np.save(path_to_model / \"true_samples.npy\", true_samples)\n",
    "np.save(path_to_model / \"generated_samples.npy\", generated_samples)\n",
    "np.save(path_to_model / \"conditioning_samples.npy\", conditioning_samples)\n",
    "\n",
    "del vdm # free up memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy-diffusion-release",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
